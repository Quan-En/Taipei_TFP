{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import os\n",
    "from itertools import chain\n",
    "from time import time\n",
    "import shutil\n",
    "import argparse\n",
    "import configparser\n",
    "from model.ASTGCN_r import make_model\n",
    "from model.LSTM import LSTM\n",
    "from lib.utils import load_graphdata_channel1, get_adjacency_matrix, compute_val_loss_mstgcn_lstm, predict_and_save_results_mstgcn_lstm\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA: True cuda:0\n",
      "folder_dir: astgcn_r_h2d2w1_channel2_1.000000e-03\n",
      "params_path: experiments/TM_COVID/astgcn_r_h2d2w1_channel2_1.000000e-03\n"
     ]
    }
   ],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(\"configurations/TMCOVID_astgcn.conf\")\n",
    "data_config = config['Data']\n",
    "training_config = config['Training']\n",
    "\n",
    "adj_filename = data_config['adj_filename']\n",
    "graph_signal_matrix_filename = data_config['graph_signal_matrix_filename']\n",
    "if config.has_option('Data', 'id_filename'):\n",
    "    id_filename = data_config['id_filename']\n",
    "else:\n",
    "    id_filename = None\n",
    "\n",
    "num_of_vertices = int(data_config['num_of_vertices'])\n",
    "points_per_hour = int(data_config['points_per_hour'])\n",
    "num_for_predict = int(data_config['num_for_predict'])\n",
    "len_input = int(data_config['len_input'])\n",
    "dataset_name = data_config['dataset_name']\n",
    "\n",
    "model_name = training_config['model_name']\n",
    "\n",
    "ctx = training_config['ctx']\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = ctx\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "DEVICE = torch.device('cuda:0' if USE_CUDA else \"cpu\")\n",
    "print(\"CUDA:\", USE_CUDA, DEVICE)\n",
    "\n",
    "learning_rate = float(training_config['learning_rate'])\n",
    "epochs = int(training_config['epochs'])\n",
    "start_epoch = int(training_config['start_epoch'])\n",
    "batch_size = int(training_config['batch_size'])\n",
    "num_of_weeks = int(training_config['num_of_weeks'])\n",
    "num_of_days = int(training_config['num_of_days'])\n",
    "num_of_hours = int(training_config['num_of_hours'])\n",
    "time_strides = 1 # num_of_hours\n",
    "nb_chev_filter = int(training_config['nb_chev_filter'])\n",
    "nb_time_filter = int(training_config['nb_time_filter'])\n",
    "in_channels = int(training_config['in_channels'])\n",
    "nb_block = int(training_config['nb_block'])\n",
    "K = int(training_config['K'])\n",
    "\n",
    "folder_dir = '%s_h%dd%dw%d_channel%d_%e' % (model_name, num_of_hours, num_of_days, num_of_weeks, in_channels, learning_rate)\n",
    "print('folder_dir:', folder_dir)\n",
    "params_path = os.path.join('experiments', dataset_name, folder_dir)\n",
    "print('params_path:', params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load file: ./data/TMCOVID/In_Out_Flow_202001_to_202105_r2_d2_w1_astcgn\n",
      "train: torch.Size([6413, 119, 2, 15]) torch.Size([6413, 119, 3])\n",
      "val: torch.Size([2138, 119, 2, 15]) torch.Size([2138, 119, 3])\n",
      "test: torch.Size([2138, 119, 2, 15]) torch.Size([2138, 119, 3])\n"
     ]
    }
   ],
   "source": [
    "train_loader, train_target_tensor, val_loader, val_target_tensor, test_loader, test_target_tensor, _mean, _std = load_graphdata_channel1(\n",
    "    graph_signal_matrix_filename, num_of_hours,\n",
    "    num_of_days, num_of_weeks, DEVICE, batch_size, True, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([32, 119, 2, 15]),\n",
       " torch.Size([32, 119, 3]),\n",
       " torch.Size([32, 7, 4])]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda x: x.shape, next(iter(train_loader)))), \n",
    "list(map(lambda x: x.shape, next(iter(val_loader)))), \n",
    "list(map(lambda x: x.shape, next(iter(test_loader))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mx, distance_mx = get_adjacency_matrix(adj_filename, num_of_vertices, id_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = make_model(DEVICE, nb_block, in_channels, K, nb_chev_filter, nb_time_filter, time_strides, adj_mx,\n",
    "                 num_for_predict, len_input, num_of_vertices)\n",
    "\n",
    "lstm_net = LSTM(input_dim=4, hidden_dim=50, num_layers=1, output_dim=119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_train_inputs, sub_train_target, sub_covid_inputs = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(device(type='cpu'), 1, 2, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE, nb_block, in_channels, K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3, 15, 119)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_strides, num_for_predict, len_input, num_of_vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 119, 2, 15])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0096, -0.0341, -2.6823],\n",
       "         [-0.7232, -1.4416, -1.3746],\n",
       "         [-0.5761, -0.3826, -2.4154],\n",
       "         ...,\n",
       "         [-0.8678, -1.3409, -1.4797],\n",
       "         [-0.9404, -1.3939, -1.4266],\n",
       "         [ 0.1402, -0.1418, -2.7332]],\n",
       "\n",
       "        [[-0.1329, -0.0467,  0.9250],\n",
       "         [-1.0710, -1.5668, -1.5094],\n",
       "         [-1.2921, -1.9157, -0.5195],\n",
       "         ...,\n",
       "         [-1.0002, -1.5352, -1.3135],\n",
       "         [-0.9398, -1.5320, -1.2586],\n",
       "         [-0.3146, -0.4813,  0.7941]],\n",
       "\n",
       "        [[ 0.0310, -1.0097, -2.8949],\n",
       "         [-0.7510, -1.5188, -1.4478],\n",
       "         [-0.2905, -1.3012, -2.3653],\n",
       "         ...,\n",
       "         [-0.9020, -1.3783, -1.4374],\n",
       "         [-0.9409, -1.3939, -1.4027],\n",
       "         [-0.1492, -1.0596, -2.6145]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.5830,  0.0898,  0.8178],\n",
       "         [-0.9678, -1.7770, -1.5016],\n",
       "         [-0.4201, -1.7359, -0.3251],\n",
       "         ...,\n",
       "         [-1.0158, -1.6495, -1.2925],\n",
       "         [-0.9447, -1.5363, -1.2988],\n",
       "         [ 0.1693, -0.5760,  0.6166]],\n",
       "\n",
       "        [[ 0.8918,  0.0694,  1.0588],\n",
       "         [ 0.4546, -1.3142, -1.8800],\n",
       "         [-0.5163, -1.9689, -1.8682],\n",
       "         ...,\n",
       "         [-0.8080, -1.5630, -1.6984],\n",
       "         [-0.8917, -1.5578, -1.3492],\n",
       "         [ 0.5788, -0.4545,  0.5569]],\n",
       "\n",
       "        [[-0.7799, -0.5395,  0.6923],\n",
       "         [-1.3145, -1.7253, -1.3942],\n",
       "         [-1.7897, -1.1856, -1.1059],\n",
       "         ...,\n",
       "         [-1.3985, -1.4673, -1.2650],\n",
       "         [-1.2041, -1.4022, -1.1172],\n",
       "         [-0.9627, -0.9650,  0.1757]]], grad_fn=<PermuteBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(sub_train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 119, 2, 15])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub_train_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_main():\n",
    "    if (start_epoch == 0) and (not os.path.exists(params_path)):\n",
    "        os.makedirs(params_path)\n",
    "        print('create params directory %s' % (params_path))\n",
    "    elif (start_epoch == 0) and (os.path.exists(params_path)):\n",
    "        shutil.rmtree(params_path)\n",
    "        os.makedirs(params_path)\n",
    "        print('delete the old one and create params directory %s' % (params_path))\n",
    "    elif (start_epoch > 0) and (os.path.exists(params_path)):\n",
    "        print('train from params directory %s' % (params_path))\n",
    "    else:\n",
    "        raise SystemExit('Wrong type of model!')\n",
    "\n",
    "    print('param list:')\n",
    "    print('CUDA\\t', DEVICE)\n",
    "    print('in_channels\\t', in_channels)\n",
    "    print('nb_block\\t', nb_block)\n",
    "    print('nb_chev_filter\\t', nb_chev_filter)\n",
    "    print('nb_time_filter\\t', nb_time_filter)\n",
    "    print('time_strides\\t', time_strides)\n",
    "    print('batch_size\\t', batch_size)\n",
    "    print('graph_signal_matrix_filename\\t', graph_signal_matrix_filename)\n",
    "    print('start_epoch\\t', start_epoch)\n",
    "    print('epochs\\t', epochs)\n",
    "\n",
    "    criterion = nn.MSELoss().to(DEVICE)\n",
    "    optimizer = optim.Adam(chain(lstm_net.parameters(), net.parameters()), lr=learning_rate)\n",
    "    sw = SummaryWriter(logdir=params_path, flush_secs=5)\n",
    "    \n",
    "    total_param = 0\n",
    "    for param_tensor in net.state_dict():\n",
    "        total_param += np.prod(net.state_dict()[param_tensor].size())\n",
    "    print('Net\\'s total params:', total_param)\n",
    "    \n",
    "    total_param = 0\n",
    "    for param_tensor in lstm_net.state_dict():\n",
    "        total_param += np.prod(lstm_net.state_dict()[param_tensor].size())\n",
    "    print('LSTM-Net\\'s total params:', total_param)\n",
    "\n",
    "    global_step = 0\n",
    "    best_epoch = 0\n",
    "    best_val_loss = np.inf\n",
    "\n",
    "    start_time = time()\n",
    "\n",
    "    if start_epoch > 0:\n",
    "\n",
    "        params_filename = os.path.join(params_path, 'epoch_%s.params' % start_epoch)\n",
    "\n",
    "        net.load_state_dict(torch.load(params_filename))\n",
    "\n",
    "        print('start epoch:', start_epoch)\n",
    "\n",
    "        print('load weight from: ', params_filename)\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(start_epoch, epochs):\n",
    "\n",
    "        params_filename = os.path.join(params_path, 'epoch_%s.params' % epoch)\n",
    "\n",
    "        val_loss = compute_val_loss_mstgcn_lstm(net, lstm_net, val_loader, criterion, sw, epoch)\n",
    "        # val_loss = compute_val_loss_mstgcn(net, val_loader, criterion, sw, epoch)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            best_epoch = epoch\n",
    "            torch.save(net.state_dict(), params_filename)\n",
    "            print('save parameters to file: %s' % params_filename)\n",
    "\n",
    "        net.train()  # ensure dropout layers are in train mode\n",
    "        lstm_net.train()\n",
    "\n",
    "        for batch_index, batch_data in enumerate(train_loader):\n",
    "\n",
    "            encoder_inputs, labels, covid_inputs = batch_data\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(encoder_inputs)\n",
    "            \n",
    "            print(\"encoder_inputs shape: \", encoder_inputs.shape)\n",
    "            print(\"outputs shape: \", outputs.shape)\n",
    "            \n",
    "            covid_weights = lstm_net(covid_inputs).unsqueeze(2)\n",
    "            \n",
    "            print(\"covid_weights shape: \", covid_weights.shape)\n",
    "            final_outputs = outputs + covid_weights * outputs\n",
    "            print(\"final_outputs shape: \", final_outputs.shape)\n",
    "            loss = criterion(final_outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss = loss.item()\n",
    "\n",
    "            global_step += 1\n",
    "\n",
    "            sw.add_scalar('training_loss', training_loss, global_step)\n",
    "\n",
    "            if global_step % 1000 == 0:\n",
    "\n",
    "                print('global step: %s, training loss: %.2f, time: %.2fs' % (global_step, training_loss, time() - start_time))\n",
    "\n",
    "    print('best epoch:', best_epoch)\n",
    "\n",
    "    # apply the best model on the test set\n",
    "    predict_main(best_epoch, test_loader, test_target_tensor, _mean, _std, 'test')\n",
    "\n",
    "def predict_main(global_step, data_loader, data_target_tensor, _mean, _std, type):\n",
    "    '''\n",
    "\n",
    "    :param global_step: int\n",
    "    :param data_loader: torch.utils.data.utils.DataLoader\n",
    "    :param data_target_tensor: tensor\n",
    "    :param mean: (1, 1, 3, 1)\n",
    "    :param std: (1, 1, 3, 1)\n",
    "    :param type: string\n",
    "    :return:\n",
    "    '''\n",
    "\n",
    "    params_filename = os.path.join(params_path, 'epoch_%s.params' % global_step)\n",
    "    print('load weight from:', params_filename)\n",
    "\n",
    "    net.load_state_dict(torch.load(params_filename))\n",
    "\n",
    "    predict_and_save_results_mstgcn_lstm(net, lstm_net, data_loader, data_target_tensor, global_step, _mean, _std, params_path, type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete the old one and create params directory experiments/TM_COVID/astgcn_r_h2d2w1_channel2_1.000000e-03\n",
      "param list:\n",
      "CUDA\t cpu\n",
      "in_channels\t 2\n",
      "nb_block\t 1\n",
      "nb_chev_filter\t 8\n",
      "nb_time_filter\t 8\n",
      "time_strides\t 2\n",
      "batch_size\t 32\n",
      "graph_signal_matrix_filename\t ./data/TMCOVID/In_Out_Flow_202001_to_202105.npy\n",
      "start_epoch\t 0\n",
      "epochs\t 80\n",
      "Net's total params: 29621\n",
      "LSTM-Net's total params: 17269\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [3, 7, 1, 8], expected input[32, 8, 119, 8] to have 7 channels, but got 8 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-4d72148c7af4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-381ed51f9d2c>\u001b[0m in \u001b[0;36mtrain_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mparams_filename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'epoch_%s.params'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_val_loss_mstgcn_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlstm_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;31m# val_loss = compute_val_loss_mstgcn(net, val_loader, criterion, sw, epoch)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SocialNetwork/final_project/lib/utils.py\u001b[0m in \u001b[0;36mcompute_val_loss_mstgcn_lstm\u001b[0;34m(net, lstm_net, val_loader, criterion, sw, epoch, limit)\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcovid_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m             \u001b[0mcovid_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovid_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/SocialNetwork/final_project/model/ASTGCN_r.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         \u001b[0;31m# (b,N,F,T)->(b,T,N,F)-conv<1,F>->(b,c_out*T,N,1)->(b,c_out*T,N)->(b,N,T)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[0;31m#         output = self.final_conv(x.permute(0, 3, 1, 2)).permute(0, 2, 1, 3)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    441\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    442\u001b[0m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0;32m--> 443\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [3, 7, 1, 8], expected input[32, 8, 119, 8] to have 7 channels, but got 8 channels instead"
     ]
    }
   ],
   "source": [
    "train_main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
